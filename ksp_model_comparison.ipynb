{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yilmajung/KM4D_v0/blob/main/ksp_model_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KSP Knowledge Extraction: Model Comparison\n",
    "\n",
    "Compare results from 3 LLMs on the same 112-chapter KSP extraction pipeline:\n",
    "\n",
    "| Model | File | Provider |\n",
    "|-------|------|----------|\n",
    "| Claude Sonnet 4 | `chapter_analysis.json` | Anthropic API |\n",
    "| Llama 3.1 8B | `chapter_analysis_llama.json` | Local (Colab T4 GPU) |\n",
    "| Llama 3.1 70B | `chapter_analysis_llama70b.json` | Together AI API |\n",
    "\n",
    "All 3 models processed the same 4 KSP reports (112 chapters) with the same prompt template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['figure.figsize'] = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect Colab vs local\n",
    "if os.path.exists('/content/drive/MyDrive/KM4D_v0/data/results'):\n",
    "    RESULTS_DIR = '/content/drive/MyDrive/KM4D_v0/data/results'\n",
    "else:\n",
    "    RESULTS_DIR = 'data/results'\n",
    "\n",
    "# Load all 3 result files\n",
    "FILES = {\n",
    "    'Claude Sonnet 4': 'chapter_analysis.json',\n",
    "    'Llama 3.1 8B': 'chapter_analysis_llama.json',\n",
    "    'Llama 3.1 70B': 'chapter_analysis_llama70b.json',\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for label, fname in FILES.items():\n",
    "    path = os.path.join(RESULTS_DIR, fname)\n",
    "    with open(path) as f:\n",
    "        results[label] = json.load(f)\n",
    "    print(f'{label}: {len(results[label])} entries loaded from {fname}')\n",
    "\n",
    "MODEL_LABELS = list(FILES.keys())\n",
    "COLORS = {'Claude Sonnet 4': '#6366f1', 'Llama 3.1 8B': '#f59e0b', 'Llama 3.1 70B': '#10b981'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Overview & Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics table\n",
    "summary_rows = []\n",
    "for model in MODEL_LABELS:\n",
    "    data = results[model]\n",
    "    total = len(data)\n",
    "    valid = [d for d in data if 'error' not in d]\n",
    "    errors = total - len(valid)\n",
    "    success_rate = len(valid) / total * 100\n",
    "\n",
    "    # Count policies (filter out placeholder \"Not Applicable\" entries)\n",
    "    total_policies = 0\n",
    "    chapters_with_policies = 0\n",
    "    for d in valid:\n",
    "        kp = d.get('korean_policies', 'Not Applicable')\n",
    "        if isinstance(kp, list):\n",
    "            real = [p for p in kp if p.get('policy_name') != 'Not Applicable']\n",
    "            if real:\n",
    "                total_policies += len(real)\n",
    "                chapters_with_policies += 1\n",
    "\n",
    "    # Count theories\n",
    "    chapters_with_theories = sum(\n",
    "        1 for d in valid\n",
    "        if isinstance(d.get('related_theories'), list) and d['related_theories']\n",
    "    )\n",
    "\n",
    "    summary_rows.append({\n",
    "        'Model': model,\n",
    "        'Total Chapters': total,\n",
    "        'Valid': len(valid),\n",
    "        'Errors': errors,\n",
    "        'Parse Success Rate': f'{success_rate:.1f}%',\n",
    "        'Total Policies': total_policies,\n",
    "        'Chapters w/ Policies': chapters_with_policies,\n",
    "        'Chapters w/ Theories': chapters_with_theories,\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "print('=== Model Comparison Summary ===')\n",
    "print()\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse success rate bar chart\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "rates = [float(row['Parse Success Rate'].strip('%')) for row in summary_rows]\n",
    "bars = ax.bar(MODEL_LABELS, rates, color=[COLORS[m] for m in MODEL_LABELS], width=0.5)\n",
    "ax.set_ylabel('Parse Success Rate (%)')\n",
    "ax.set_title('JSON Parse Success Rate by Model')\n",
    "ax.set_ylim(0, 110)\n",
    "for bar, rate in zip(bars, rates):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1.5,\n",
    "            f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Sector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sector normalization for Llama 8B\n",
    "# The 8B model omits \"(N)\" prefixes and sometimes uses sub-sector L1 names as sector names.\n",
    "# Build a lookup mapping every sub-sector name back to its parent sector.\n",
    "\n",
    "TAXONOMY = {\n",
    "    '(1) Economic Policy': {\n",
    "        'Macroeconomic Policy & Stability': {},\n",
    "        'Inclusive & Sustainable Growth': {},\n",
    "        'Investment & Private Sector Dev.': {},\n",
    "    },\n",
    "    '(2) Social Services': {\n",
    "        'Education': {},\n",
    "        'Health': {},\n",
    "        'Social Protection & Inclusion': {},\n",
    "        'Cross-Cutting Social Issues': {},\n",
    "    },\n",
    "    '(3) Digital Innovation': {\n",
    "        'Digital Policy & Governance': {},\n",
    "        'Digital Infrastructure': {},\n",
    "        'Digital Transformation': {},\n",
    "        'Emerging Technologies': {},\n",
    "    },\n",
    "    '(4) Production & Trade': {\n",
    "        'Agriculture, Forestry & Fisheries': {},\n",
    "        'Industry & Services': {},\n",
    "        'Trade Policy & Facilitation': {},\n",
    "    },\n",
    "    '(5) Infrastructure': {\n",
    "        'Infrastructure Policy & Finance': {},\n",
    "        'Transport': {},\n",
    "        'Water & Sanitation': {},\n",
    "        'Urban & Rural Development': {},\n",
    "    },\n",
    "    '(6) Energy & Environment': {\n",
    "        'Environmental Policy & Management': {},\n",
    "        'Climate Change': {},\n",
    "        'Energy': {},\n",
    "    },\n",
    "}\n",
    "\n",
    "SECTOR_NAMES = list(TAXONOMY.keys())  # canonical names with prefixes\n",
    "\n",
    "# Build normalization lookup\n",
    "_sector_lookup = {}\n",
    "for sector, l1_dict in TAXONOMY.items():\n",
    "    # Map unprefixed name -> canonical\n",
    "    short_name = sector.split(') ', 1)[1] if ') ' in sector else sector\n",
    "    _sector_lookup[short_name.lower()] = sector\n",
    "    _sector_lookup[sector.lower()] = sector\n",
    "    # Map every sub-sector L1 name -> parent sector\n",
    "    for l1_name in l1_dict:\n",
    "        _sector_lookup[l1_name.lower()] = sector\n",
    "\n",
    "\n",
    "def normalize_sector(name: str) -> str:\n",
    "    \"\"\"Normalize a sector name to its canonical form with (N) prefix.\"\"\"\n",
    "    if not name:\n",
    "        return 'Unknown'\n",
    "    # Already canonical?\n",
    "    if name in SECTOR_NAMES:\n",
    "        return name\n",
    "    # Lookup\n",
    "    result = _sector_lookup.get(name.lower())\n",
    "    if result:\n",
    "        return result\n",
    "    return f'Unknown ({name})'\n",
    "\n",
    "\n",
    "# Test normalization\n",
    "test_cases = [\n",
    "    'Economic Policy',\n",
    "    '(1) Economic Policy',\n",
    "    'Inclusive & Sustainable Growth',\n",
    "    'Investment & Private Sector Dev.',\n",
    "    'Production & Trade',\n",
    "    'Digital Innovation',\n",
    "    'Energy & Environment',\n",
    "]\n",
    "print('Sector normalization test:')\n",
    "for name in test_cases:\n",
    "    print(f'  \"{name}\" -> \"{normalize_sector(name)}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sector distribution across 3 models (grouped bar chart)\n",
    "def get_sector_counts(data):\n",
    "    counts = Counter()\n",
    "    for d in data:\n",
    "        if 'error' not in d:\n",
    "            sectors = d['taxonomy_classification']['sectors']\n",
    "            if sectors:\n",
    "                primary = normalize_sector(sectors[0]['sector'])\n",
    "                counts[primary] += 1\n",
    "    return counts\n",
    "\n",
    "sector_data = {model: get_sector_counts(results[model]) for model in MODEL_LABELS}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "x = np.arange(len(SECTOR_NAMES))\n",
    "width = 0.25\n",
    "for i, model in enumerate(MODEL_LABELS):\n",
    "    counts = [sector_data[model].get(s, 0) for s in SECTOR_NAMES]\n",
    "    ax.bar(x + i * width, counts, width, label=model, color=COLORS[model])\n",
    "\n",
    "ax.set_xlabel('Sector')\n",
    "ax.set_ylabel('Number of Chapters')\n",
    "ax.set_title('Primary Sector Distribution by Model')\n",
    "ax.set_xticks(x + width)\n",
    "# Wrap long sector names\n",
    "short_labels = [s.replace('(', '\\n(').strip() for s in SECTOR_NAMES]\n",
    "ax.set_xticklabels(short_labels, fontsize=8)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Chapter-level sector agreement\n# Use (report_id, chapter_title, page_start) as key â€” title alone is not unique\n# because sub-chapters like \"1. Introduction\" repeat within the same report.\n\ndef chapter_key(d):\n    \"\"\"Unique key for a chapter entry.\"\"\"\n    return (d['report_id'], d['chapter_title'], d['page_start'])\n\ndef get_chapter_sectors(data):\n    \"\"\"Return dict mapping chapter_key -> normalized primary sector.\"\"\"\n    mapping = {}\n    for d in data:\n        if 'error' not in d:\n            key = chapter_key(d)\n            sectors = d['taxonomy_classification']['sectors']\n            if sectors:\n                mapping[key] = normalize_sector(sectors[0]['sector'])\n    return mapping\n\nsector_maps = {model: get_chapter_sectors(results[model]) for model in MODEL_LABELS}\n\n# Find chapters where ALL 3 models have valid results\ncommon_keys = set.intersection(*[set(m.keys()) for m in sector_maps.values()])\nprint(f'Chapters with valid results from all 3 models: {len(common_keys)}')\nprint()\n\n# Full agreement\nfull_agree = sum(\n    1 for k in common_keys\n    if len({sector_maps[m][k] for m in MODEL_LABELS}) == 1\n)\nprint(f'Full agreement (all 3 match): {full_agree}/{len(common_keys)} ({full_agree/len(common_keys)*100:.1f}%)')\n\n# Pairwise agreement\npairs = [\n    ('Claude Sonnet 4', 'Llama 3.1 70B'),\n    ('Claude Sonnet 4', 'Llama 3.1 8B'),\n    ('Llama 3.1 70B', 'Llama 3.1 8B'),\n]\nfor m1, m2 in pairs:\n    agree = sum(1 for k in common_keys if sector_maps[m1][k] == sector_maps[m2][k])\n    print(f'  {m1} vs {m2}: {agree}/{len(common_keys)} ({agree/len(common_keys)*100:.1f}%)')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Knowledge Type Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge type distribution (grouped bar chart)\n",
    "KNOWLEDGE_TYPES = [\n",
    "    'Policy Entrepreneurship (leadership)',\n",
    "    'Policy Implementation & Coordinating Mechanism',\n",
    "    'Organizational/Individual Capacity',\n",
    "    'Technical Know-how',\n",
    "]\n",
    "\n",
    "def get_kt_counts(data):\n",
    "    counts = Counter()\n",
    "    for d in data:\n",
    "        if 'error' not in d:\n",
    "            kt = d['taxonomy_classification']['knowledge_type']\n",
    "            counts[kt] += 1\n",
    "    return counts\n",
    "\n",
    "kt_data = {model: get_kt_counts(results[model]) for model in MODEL_LABELS}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "x = np.arange(len(KNOWLEDGE_TYPES))\n",
    "width = 0.25\n",
    "for i, model in enumerate(MODEL_LABELS):\n",
    "    counts = [kt_data[model].get(kt, 0) for kt in KNOWLEDGE_TYPES]\n",
    "    ax.bar(x + i * width, counts, width, label=model, color=COLORS[model])\n",
    "\n",
    "ax.set_xlabel('Knowledge Type')\n",
    "ax.set_ylabel('Number of Chapters')\n",
    "ax.set_title('Knowledge Type Distribution by Model')\n",
    "ax.set_xticks(x + width)\n",
    "# Shorter labels\n",
    "kt_short = ['Policy\\nEntrepreneurship', 'Policy\\nImplementation', 'Organizational\\nCapacity', 'Technical\\nKnow-how']\n",
    "ax.set_xticklabels(kt_short, fontsize=9)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Chapter-level knowledge type agreement\ndef get_chapter_kt(data):\n    mapping = {}\n    for d in data:\n        if 'error' not in d:\n            key = chapter_key(d)\n            mapping[key] = d['taxonomy_classification']['knowledge_type']\n    return mapping\n\nkt_maps = {model: get_chapter_kt(results[model]) for model in MODEL_LABELS}\ncommon_keys_kt = set.intersection(*[set(m.keys()) for m in kt_maps.values()])\n\nfull_agree_kt = sum(\n    1 for k in common_keys_kt\n    if len({kt_maps[m][k] for m in MODEL_LABELS}) == 1\n)\nprint(f'Knowledge type agreement (all 3 match): {full_agree_kt}/{len(common_keys_kt)} ({full_agree_kt/len(common_keys_kt)*100:.1f}%)')\n\nfor m1, m2 in pairs:\n    agree = sum(1 for k in common_keys_kt if kt_maps[m1][k] == kt_maps[m2][k])\n    print(f'  {m1} vs {m2}: {agree}/{len(common_keys_kt)} ({agree/len(common_keys_kt)*100:.1f}%)')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Korean Policy Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-report policy count comparison\n",
    "def get_policy_counts_by_report(data):\n",
    "    counts = Counter()\n",
    "    for d in data:\n",
    "        if 'error' not in d:\n",
    "            kp = d.get('korean_policies', 'Not Applicable')\n",
    "            if isinstance(kp, list):\n",
    "                real = [p for p in kp if p.get('policy_name') != 'Not Applicable']\n",
    "                counts[d['report_id']] += len(real)\n",
    "    return counts\n",
    "\n",
    "policy_data = {model: get_policy_counts_by_report(results[model]) for model in MODEL_LABELS}\n",
    "\n",
    "# Short report labels\n",
    "all_reports = sorted({d['report_id'] for d in results[MODEL_LABELS[0]]})\n",
    "report_short = {r: r[:8] for r in all_reports}  # e.g. \"2009_VNM\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(all_reports))\n",
    "width = 0.25\n",
    "for i, model in enumerate(MODEL_LABELS):\n",
    "    counts = [policy_data[model].get(r, 0) for r in all_reports]\n",
    "    ax.bar(x + i * width, counts, width, label=model, color=COLORS[model])\n",
    "\n",
    "ax.set_xlabel('KSP Report')\n",
    "ax.set_ylabel('Number of Policies Extracted')\n",
    "ax.set_title('Korean Policy Extraction by Report and Model')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels([report_short[r] for r in all_reports], fontsize=9)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Policy extraction: which chapters found policies by which models\ndef get_chapters_with_policies(data):\n    chapters = set()\n    for d in data:\n        if 'error' not in d:\n            kp = d.get('korean_policies', 'Not Applicable')\n            if isinstance(kp, list):\n                real = [p for p in kp if p.get('policy_name') != 'Not Applicable']\n                if real:\n                    chapters.add(chapter_key(d))\n    return chapters\n\npolicy_chapters = {model: get_chapters_with_policies(results[model]) for model in MODEL_LABELS}\n\n# Overlap analysis (using common valid chapters only)\ncommon_valid = set.intersection(*[\n    {chapter_key(d) for d in results[m] if 'error' not in d}\n    for m in MODEL_LABELS\n])\n\nprint(f'Common valid chapters: {len(common_valid)}')\nprint()\n\n# Restrict to common chapters\npc_common = {m: policy_chapters[m] & common_valid for m in MODEL_LABELS}\n\nfor model in MODEL_LABELS:\n    print(f'{model}: {len(pc_common[model])} chapters with policies (out of {len(common_valid)} common)')\n\nprint()\n\n# All 3 found policies\nall_found = set.intersection(*pc_common.values()) if all(pc_common.values()) else set()\nprint(f'All 3 models found policies: {len(all_found)} chapters')\n\n# Only one model found policies\nfor model in MODEL_LABELS:\n    others = [m for m in MODEL_LABELS if m != model]\n    unique = pc_common[model] - set.union(*[pc_common[m] for m in others])\n    print(f'Only {model} found policies: {len(unique)} chapters')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Theory Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theory linking rate by model\n",
    "print('Theory Linking Summary')\n",
    "print('=' * 60)\n",
    "print()\n",
    "\n",
    "theory_stats = []\n",
    "for model in MODEL_LABELS:\n",
    "    valid = [d for d in results[model] if 'error' not in d]\n",
    "    with_theories = [\n",
    "        d for d in valid\n",
    "        if isinstance(d.get('related_theories'), list) and d['related_theories']\n",
    "    ]\n",
    "    total_theories = sum(\n",
    "        len(d['related_theories']) for d in with_theories\n",
    "    )\n",
    "    avg = total_theories / len(with_theories) if with_theories else 0\n",
    "\n",
    "    theory_stats.append({\n",
    "        'Model': model,\n",
    "        'Valid Chapters': len(valid),\n",
    "        'Chapters w/ Theories': len(with_theories),\n",
    "        'Linking Rate': f'{len(with_theories)/len(valid)*100:.1f}%',\n",
    "        'Total Theories Cited': total_theories,\n",
    "        'Avg Theories/Chapter': f'{avg:.1f}',\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(theory_stats).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Chapter-Level Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Side-by-side comparison for a sample of chapters\n# Pick 10 chapters spread across reports where all 3 models have results\n\n# Build lookup by chapter key\nlookups = {}\nfor model in MODEL_LABELS:\n    lookups[model] = {}\n    for d in results[model]:\n        if 'error' not in d:\n            key = chapter_key(d)\n            lookups[model][key] = d\n\ncommon = sorted(common_valid)\n# Sample evenly: pick every Nth chapter\nstep = max(1, len(common) // 10)\nsample_keys = common[::step][:10]\n\nrows = []\nfor key in sample_keys:\n    report_id, chapter_title, page_start = key\n    row = {\n        'Report': report_id[:8],\n        'Chapter': chapter_title[:50],\n    }\n    for model in MODEL_LABELS:\n        d = lookups[model][key]\n        sectors = d['taxonomy_classification']['sectors']\n        primary_sector = normalize_sector(sectors[0]['sector']) if sectors else 'N/A'\n        # Short sector label (just the number)\n        sector_short = primary_sector.split(')')[0] + ')' if '(' in primary_sector else primary_sector\n        kt = d['taxonomy_classification']['knowledge_type']\n        # Abbreviate knowledge type\n        kt_abbrev = {\n            'Policy Entrepreneurship (leadership)': 'Entrepreneurship',\n            'Policy Implementation & Coordinating Mechanism': 'Implementation',\n            'Organizational/Individual Capacity': 'Org. Capacity',\n            'Technical Know-how': 'Technical',\n        }.get(kt, kt)\n\n        kp = d.get('korean_policies', 'Not Applicable')\n        if isinstance(kp, list):\n            n_policies = len([p for p in kp if p.get('policy_name') != 'Not Applicable'])\n        else:\n            n_policies = 0\n\n        short_model = model.split()[-1]  # \"4\", \"8B\", \"70B\"\n        row[f'{short_model} Sector'] = sector_short\n        row[f'{short_model} KT'] = kt_abbrev\n        row[f'{short_model} Pol'] = n_policies\n\n    rows.append(row)\n\ndetail_df = pd.DataFrame(rows)\nprint('=== Side-by-Side Chapter Comparison (sample of 10) ===')\nprint()\npd.set_option('display.max_colwidth', 50)\npd.set_option('display.width', 200)\nprint(detail_df.to_string(index=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary findings\n",
    "print('=' * 70)\n",
    "print('MODEL COMPARISON SUMMARY')\n",
    "print('=' * 70)\n",
    "print()\n",
    "\n",
    "# 1. Reliability\n",
    "print('1. RELIABILITY')\n",
    "print('-' * 40)\n",
    "for row in summary_rows:\n",
    "    print(f\"   {row['Model']}: {row['Parse Success Rate']} parse success ({row['Errors']} errors)\")\n",
    "print()\n",
    "\n",
    "# 2. Sector agreement\n",
    "print('2. SECTOR CLASSIFICATION AGREEMENT')\n",
    "print('-' * 40)\n",
    "print(f'   Full agreement (all 3): {full_agree}/{len(common_keys)} ({full_agree/len(common_keys)*100:.1f}%)')\n",
    "for m1, m2 in pairs:\n",
    "    agree = sum(1 for k in common_keys if sector_maps[m1][k] == sector_maps[m2][k])\n",
    "    print(f'   {m1} vs {m2}: {agree/len(common_keys)*100:.1f}%')\n",
    "print()\n",
    "\n",
    "# 3. Knowledge type agreement\n",
    "print('3. KNOWLEDGE TYPE AGREEMENT')\n",
    "print('-' * 40)\n",
    "print(f'   Full agreement (all 3): {full_agree_kt}/{len(common_keys_kt)} ({full_agree_kt/len(common_keys_kt)*100:.1f}%)')\n",
    "for m1, m2 in pairs:\n",
    "    agree = sum(1 for k in common_keys_kt if kt_maps[m1][k] == kt_maps[m2][k])\n",
    "    print(f'   {m1} vs {m2}: {agree/len(common_keys_kt)*100:.1f}%')\n",
    "print()\n",
    "\n",
    "# 4. Key differences\n",
    "print('4. KEY DIFFERENCES')\n",
    "print('-' * 40)\n",
    "print('   - Knowledge type skew: Sonnet favors \"Technical Know-how\",'\n",
    "      ' Llama models favor \"Policy Implementation\"')\n",
    "print(f'   - Policy extraction volume: Sonnet ({summary_rows[0][\"Total Policies\"]}) >>'\n",
    "      f' 70B ({summary_rows[2][\"Total Policies\"]}) > 8B ({summary_rows[1][\"Total Policies\"]})')\n",
    "print(f'   - 8B reliability: only {summary_rows[1][\"Parse Success Rate\"]} parse success'\n",
    "      ' (JSON formatting issues)')\n",
    "print()\n",
    "\n",
    "# 5. Recommendations\n",
    "print('5. RECOMMENDATIONS')\n",
    "print('-' * 40)\n",
    "print('   - Claude Sonnet 4: Best reliability and richest extraction.')\n",
    "print('     Recommended for production pipeline.')\n",
    "print('   - Llama 3.1 70B: Good reliability (97.3%), reasonable extraction.')\n",
    "print('     Viable open-source alternative with structured output tuning.')\n",
    "print('   - Llama 3.1 8B: Too many parse failures for production use.')\n",
    "print('     Needs structured output enforcement or fine-tuning.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}